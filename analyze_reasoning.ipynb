{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from trl import GRPOConfig, GRPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA GPU backend True\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA GPU backend\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['pubid', 'question', 'context', 'long_answer'],\n",
      "        num_rows: 61249\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ds = load_dataset(\"qiaojin/PubMedQA\", \"pqa_unlabeled\")\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['long_answer', 'prompt'],\n",
      "        num_rows: 61249\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = (\n",
    "    \"A conversation between User and Assistant. The user asks a question, and given a context, the Assistant solves it. The assistant \"\n",
    "    \"first thinks about the context, then runs a reasoning process in the mind and finally provides the user with the answer. The reasoning \"\n",
    "    \"process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., \"\n",
    "    \"<think> reasoning process here </think><answer> answer here </answer>\"\n",
    ")\n",
    "\n",
    "def make_conversation(example):\n",
    "    return {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": \"\".join(example[\"context\"]['contexts'])},\n",
    "            {\"role\": \"user\", \"content\": example[\"question\"]},\n",
    "        ],\n",
    "    }\n",
    "\n",
    "ds = ds.map(make_conversation)\n",
    "train_dataset = ds.remove_columns(['pubid', 'question', 'context'])\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reasoning_and_graph(example):\n",
    "    prompt_text = example[\"prompt\"]\n",
    "    input_text = \"\\n\".join([entry[\"content\"] for entry in prompt_text])\n",
    "    print(\"input\", input_text)\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    print(\"input tokens\", inputs)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=300)\n",
    "    print(\"outputs\", outputs)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(\"response\", response)\n",
    "    \n",
    "    # Extract reasoning using regex\n",
    "    think_match = re.search(r\"<think>(.*?)</think>\", response, re.DOTALL)\n",
    "    reasoning_process = think_match.group(1) if think_match else \"\"\n",
    "    \n",
    "    # Convert reasoning into a simple graph (JSON format)\n",
    "    graph_structure = {\"nodes\": [], \"edges\": []}\n",
    "    steps = reasoning_process.split(\". \")\n",
    "    for i, step in enumerate(steps):\n",
    "        graph_structure[\"nodes\"].append({\"id\": i, \"text\": step})\n",
    "        if i > 0:\n",
    "            graph_structure[\"edges\"].append({\"source\": i - 1, \"target\": i})\n",
    "    \n",
    "    return {\"reasoning_graph\": json.dumps(graph_structure), \"model_response\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6edcb591fa40ba9cf1eb600124d449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input A conversation between User and Assistant. The user asks a question, and given a context, the Assistant solves it. The assistant first thinks about the context, then runs a reasoning process in the mind and finally provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think><answer> answer here </answer>\n",
      "Although the use of alternative medicine in the United States is increasing, no published studies have documented the effectiveness of naturopathy for treatment of menopausal symptoms compared to women receiving conventional therapy in the clinical setting.To compare naturopathic therapy with conventional medical therapy for treatment of selected menopausal symptoms.A retrospective cohort study, using abstracted data from medical charts.One natural medicine and six conventional medical clinics at Community Health Centers of King County, Washington, from November 1, 1996, through July 31, 1998.Women aged 40 years of age or more with a diagnosis of menopausal symptoms documented by a naturopathic or conventional physician.Improvement in selected menopausal symptoms.In univariate analyses, patients treated with naturopathy for menopausal symptoms reported higher monthly incomes ($1848.00 versus $853.60), were less likely to be smokers (11.4% versus 41.9%), exercised more frequently, and reported higher frequencies of decreased energy (41.8% versus 24.4%), insomnia (57.0% versus 33.1%), and hot flashes (69.6% versus 55.6%) at baseline than those who received conventional treatment. In multivariate analyses, patients treated with naturopathy were approximately seven times more likely than conventionally treated patients to report improvement for insomnia (odds ratio [OR], 6.77; 95% confidence interval [CI], 1.71, 26.63) and decreased energy (OR, 6.55; 95% CI, 0.96, 44.74). Naturopathy patients reported improvement for anxiety (OR, 1.27; 95% CI, 0.63, 2.56), hot flashes (OR, 1.40; 95% CI, 0.68, 2.88), menstrual changes (OR, 0.98; 95% CI, 0.43, 2.24), and vaginal dryness (OR, 0.91; 95% CI, 0.21, 3.96) about as frequently as patients who were treated conventionally.\n",
      "Is naturopathy as effective as conventional therapy for treatment of menopausal symptoms?\n",
      "input tokens {'input_ids': tensor([[151646,     32,  10435,   1948,   2657,    323,  21388,     13,    576,\n",
      "           1196,  17064,    264,   3405,     11,    323,   2661,    264,   2266,\n",
      "             11,    279,  21388,  67477,    432,     13,    576,  17847,   1156,\n",
      "          15482,    911,    279,   2266,     11,   1221,   8473,    264,  32711,\n",
      "           1882,    304,    279,   3971,    323,   5499,   5707,    279,   1196,\n",
      "            448,    279,   4226,     13,    576,  32711,   1882,    323,   4226,\n",
      "            525,  43810,   2878,    220, 151648,    220, 151649,    323,    366,\n",
      "           9217,     29,    690,   9217,     29,   9492,     11,  15576,     11,\n",
      "            600,   1734,   2572,    220, 151648,  32711,   1882,   1588,    220,\n",
      "         151649,     27,   9217,     29,   4226,   1588,    690,   9217,    397,\n",
      "          15802,    279,    990,    315,  10555,  15712,    304,    279,   3639,\n",
      "           4180,    374,   7703,     11,    902,   4652,   7822,    614,  26372,\n",
      "            279,  26279,    315,  17588,     84,    887,  19135,    369,   6380,\n",
      "            315,   2953,    453,  79074,  13495,   7707,    311,   3198,  12308,\n",
      "          20692,  15069,    304,    279,  14490,   6243,   3274,   9429,  17588,\n",
      "             84,    887,    587,    292,  15069,    448,  20692,   6457,  15069,\n",
      "            369,   6380,    315,   4091,   2953,    453,  79074,  13495,    875,\n",
      "          78829,  40844,   3920,     11,   1667,   8115,    291,    821,    504,\n",
      "           6457,  26131,  37067,   5810,  15712,    323,   4743,  20692,   6457,\n",
      "          43235,    518,  12062,   6267,  40891,    315,   6210,   6272,     11,\n",
      "           6515,     11,    504,   6702,    220,     16,     11,    220,     16,\n",
      "             24,     24,     21,     11,   1526,   5768,    220,     18,     16,\n",
      "             11,    220,     16,     24,     24,     23,   1175,   6297,  19749,\n",
      "            220,     19,     15,   1635,    315,   4231,    476,    803,    448,\n",
      "            264,  22982,    315,   2953,    453,  79074,  13495,  26372,    553,\n",
      "            264,  17588,     84,    887,    587,    292,    476,  20692,  27279,\n",
      "          26914,    776,   7830,    304,   4091,   2953,    453,  79074,  13495,\n",
      "           5337,    650,  55422,  27960,     11,   6835,  11758,    448,  17588,\n",
      "             84,    887,  19135,    369,   2953,    453,  79074,  13495,   4961,\n",
      "           5080,  15088,  45691,   1711,     16,     23,     19,     23,     13,\n",
      "             15,     15,  19041,    400,     23,     20,     18,     13,     21,\n",
      "             15,    701,   1033,   2686,   4363,    311,    387,  56657,    320,\n",
      "             16,     16,     13,     19,      4,  19041,    220,     19,     16,\n",
      "             13,     24,  33871,  61013,    803,  13814,     11,    323,   4961,\n",
      "           5080,  33773,    315,  24938,   4802,    320,     19,     16,     13,\n",
      "             23,      4,  19041,    220,     17,     19,     13,     19,  33871,\n",
      "          82411,    320,     20,     22,     13,     15,      4,  19041,    220,\n",
      "             18,     18,     13,     16,  33871,    323,   4017,  61285,    320,\n",
      "             21,     24,     13,     21,      4,  19041,    220,     20,     20,\n",
      "             13,     21,  11334,    518,  25869,   1091,   1846,    879,   3949,\n",
      "          20692,   6380,     13,    758,   2745,  55422,  27960,     11,   6835,\n",
      "          11758,    448,  17588,     84,    887,  19135,   1033,  13187,   8094,\n",
      "           3039,    803,   4363,   1091,  21277,    745,  11758,   6835,    311,\n",
      "           1895,  15673,    369,  82411,    320,    347,   5356,  11341,    508,\n",
      "            868,   1125,    220,     21,     13,     22,     22,     26,    220,\n",
      "             24,     20,      4,  12136,   9873,    508,  11237,   1125,    220,\n",
      "             16,     13,     22,     16,     11,    220,     17,     21,     13,\n",
      "             21,     18,      8,    323,  24938,   4802,    320,    868,     11,\n",
      "            220,     21,     13,     20,     20,     26,    220,     24,     20,\n",
      "              4,  20694,     11,    220,     15,     13,     24,     21,     11,\n",
      "            220,     19,     19,     13,     22,     19,    568,  23833,     84,\n",
      "            887,  19135,   6835,   4961,  15673,    369,  18056,    320,    868,\n",
      "             11,    220,     16,     13,     17,     22,     26,    220,     24,\n",
      "             20,      4,  20694,     11,    220,     15,     13,     21,     18,\n",
      "             11,    220,     17,     13,     20,     21,    701,   4017,  61285,\n",
      "            320,    868,     11,    220,     16,     13,     19,     15,     26,\n",
      "            220,     24,     20,      4,  20694,     11,    220,     15,     13,\n",
      "             21,     23,     11,    220,     17,     13,     23,     23,    701,\n",
      "          77627,   4344,    320,    868,     11,    220,     15,     13,     24,\n",
      "             23,     26,    220,     24,     20,      4,  20694,     11,    220,\n",
      "             15,     13,     19,     18,     11,    220,     17,     13,     17,\n",
      "             19,    701,    323,  57059,   9058,   2090,    320,    868,     11,\n",
      "            220,     15,     13,     24,     16,     26,    220,     24,     20,\n",
      "              4,  20694,     11,    220,     15,     13,     17,     16,     11,\n",
      "            220,     18,     13,     24,     21,      8,    911,    438,  13814,\n",
      "            438,   6835,    879,   1033,  11758,  21277,    745,    624,   3872,\n",
      "          17588,     84,    887,  19135,    438,   7373,    438,  20692,  15069,\n",
      "            369,   6380,    315,   2953,    453,  79074,  13495,     30]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs tensor([[151646,     32,  10435,   1948,   2657,    323,  21388,     13,    576,\n",
      "           1196,  17064,    264,   3405,     11,    323,   2661,    264,   2266,\n",
      "             11,    279,  21388,  67477,    432,     13,    576,  17847,   1156,\n",
      "          15482,    911,    279,   2266,     11,   1221,   8473,    264,  32711,\n",
      "           1882,    304,    279,   3971,    323,   5499,   5707,    279,   1196,\n",
      "            448,    279,   4226,     13,    576,  32711,   1882,    323,   4226,\n",
      "            525,  43810,   2878,    220, 151648,    220, 151649,    323,    366,\n",
      "           9217,     29,    690,   9217,     29,   9492,     11,  15576,     11,\n",
      "            600,   1734,   2572,    220, 151648,  32711,   1882,   1588,    220,\n",
      "         151649,     27,   9217,     29,   4226,   1588,    690,   9217,    397,\n",
      "          15802,    279,    990,    315,  10555,  15712,    304,    279,   3639,\n",
      "           4180,    374,   7703,     11,    902,   4652,   7822,    614,  26372,\n",
      "            279,  26279,    315,  17588,     84,    887,  19135,    369,   6380,\n",
      "            315,   2953,    453,  79074,  13495,   7707,    311,   3198,  12308,\n",
      "          20692,  15069,    304,    279,  14490,   6243,   3274,   9429,  17588,\n",
      "             84,    887,    587,    292,  15069,    448,  20692,   6457,  15069,\n",
      "            369,   6380,    315,   4091,   2953,    453,  79074,  13495,    875,\n",
      "          78829,  40844,   3920,     11,   1667,   8115,    291,    821,    504,\n",
      "           6457,  26131,  37067,   5810,  15712,    323,   4743,  20692,   6457,\n",
      "          43235,    518,  12062,   6267,  40891,    315,   6210,   6272,     11,\n",
      "           6515,     11,    504,   6702,    220,     16,     11,    220,     16,\n",
      "             24,     24,     21,     11,   1526,   5768,    220,     18,     16,\n",
      "             11,    220,     16,     24,     24,     23,   1175,   6297,  19749,\n",
      "            220,     19,     15,   1635,    315,   4231,    476,    803,    448,\n",
      "            264,  22982,    315,   2953,    453,  79074,  13495,  26372,    553,\n",
      "            264,  17588,     84,    887,    587,    292,    476,  20692,  27279,\n",
      "          26914,    776,   7830,    304,   4091,   2953,    453,  79074,  13495,\n",
      "           5337,    650,  55422,  27960,     11,   6835,  11758,    448,  17588,\n",
      "             84,    887,  19135,    369,   2953,    453,  79074,  13495,   4961,\n",
      "           5080,  15088,  45691,   1711,     16,     23,     19,     23,     13,\n",
      "             15,     15,  19041,    400,     23,     20,     18,     13,     21,\n",
      "             15,    701,   1033,   2686,   4363,    311,    387,  56657,    320,\n",
      "             16,     16,     13,     19,      4,  19041,    220,     19,     16,\n",
      "             13,     24,  33871,  61013,    803,  13814,     11,    323,   4961,\n",
      "           5080,  33773,    315,  24938,   4802,    320,     19,     16,     13,\n",
      "             23,      4,  19041,    220,     17,     19,     13,     19,  33871,\n",
      "          82411,    320,     20,     22,     13,     15,      4,  19041,    220,\n",
      "             18,     18,     13,     16,  33871,    323,   4017,  61285,    320,\n",
      "             21,     24,     13,     21,      4,  19041,    220,     20,     20,\n",
      "             13,     21,  11334,    518,  25869,   1091,   1846,    879,   3949,\n",
      "          20692,   6380,     13,    758,   2745,  55422,  27960,     11,   6835,\n",
      "          11758,    448,  17588,     84,    887,  19135,   1033,  13187,   8094,\n",
      "           3039,    803,   4363,   1091,  21277,    745,  11758,   6835,    311,\n",
      "           1895,  15673,    369,  82411,    320,    347,   5356,  11341,    508,\n",
      "            868,   1125,    220,     21,     13,     22,     22,     26,    220,\n",
      "             24,     20,      4,  12136,   9873,    508,  11237,   1125,    220,\n",
      "             16,     13,     22,     16,     11,    220,     17,     21,     13,\n",
      "             21,     18,      8,    323,  24938,   4802,    320,    868,     11,\n",
      "            220,     21,     13,     20,     20,     26,    220,     24,     20,\n",
      "              4,  20694,     11,    220,     15,     13,     24,     21,     11,\n",
      "            220,     19,     19,     13,     22,     19,    568,  23833,     84,\n",
      "            887,  19135,   6835,   4961,  15673,    369,  18056,    320,    868,\n",
      "             11,    220,     16,     13,     17,     22,     26,    220,     24,\n",
      "             20,      4,  20694,     11,    220,     15,     13,     21,     18,\n",
      "             11,    220,     17,     13,     20,     21,    701,   4017,  61285,\n",
      "            320,    868,     11,    220,     16,     13,     19,     15,     26,\n",
      "            220,     24,     20,      4,  20694,     11,    220,     15,     13,\n",
      "             21,     23,     11,    220,     17,     13,     23,     23,    701,\n",
      "          77627,   4344,    320,    868,     11,    220,     15,     13,     24,\n",
      "             23,     26,    220,     24,     20,      4,  20694,     11,    220,\n",
      "             15,     13,     19,     18,     11,    220,     17,     13,     17,\n",
      "             19,    701,    323,  57059,   9058,   2090,    320,    868,     11,\n",
      "            220,     15,     13,     24,     16,     26,    220,     24,     20,\n",
      "              4,  20694,     11,    220,     15,     13,     17,     16,     11,\n",
      "            220,     18,     13,     24,     21,      8,    911,    438,  13814,\n",
      "            438,   6835,    879,   1033,  11758,  21277,    745,    624,   3872,\n",
      "          17588,     84,    887,  19135,    438,   7373,    438,  20692,  15069,\n",
      "            369,   6380,    315,   2953,    453,  79074,  13495,     30,    366,\n",
      "           9217,     29, 151643]])\n",
      "response A conversation between User and Assistant. The user asks a question, and given a context, the Assistant solves it. The assistant first thinks about the context, then runs a reasoning process in the mind and finally provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think><answer> answer here </answer>\n",
      "Although the use of alternative medicine in the United States is increasing, no published studies have documented the effectiveness of naturopathy for treatment of menopausal symptoms compared to women receiving conventional therapy in the clinical setting.To compare naturopathic therapy with conventional medical therapy for treatment of selected menopausal symptoms.A retrospective cohort study, using abstracted data from medical charts.One natural medicine and six conventional medical clinics at Community Health Centers of King County, Washington, from November 1, 1996, through July 31, 1998.Women aged 40 years of age or more with a diagnosis of menopausal symptoms documented by a naturopathic or conventional physician.Improvement in selected menopausal symptoms.In univariate analyses, patients treated with naturopathy for menopausal symptoms reported higher monthly incomes ($1848.00 versus $853.60), were less likely to be smokers (11.4% versus 41.9%), exercised more frequently, and reported higher frequencies of decreased energy (41.8% versus 24.4%), insomnia (57.0% versus 33.1%), and hot flashes (69.6% versus 55.6%) at baseline than those who received conventional treatment. In multivariate analyses, patients treated with naturopathy were approximately seven times more likely than conventionally treated patients to report improvement for insomnia (odds ratio [OR], 6.77; 95% confidence interval [CI], 1.71, 26.63) and decreased energy (OR, 6.55; 95% CI, 0.96, 44.74). Naturopathy patients reported improvement for anxiety (OR, 1.27; 95% CI, 0.63, 2.56), hot flashes (OR, 1.40; 95% CI, 0.68, 2.88), menstrual changes (OR, 0.98; 95% CI, 0.43, 2.24), and vaginal dryness (OR, 0.91; 95% CI, 0.21, 3.96) about as frequently as patients who were treated conventionally.\n",
      "Is naturopathy as effective as conventional therapy for treatment of menopausal symptoms? <answer>\n",
      "input A conversation between User and Assistant. The user asks a question, and given a context, the Assistant solves it. The assistant first thinks about the context, then runs a reasoning process in the mind and finally provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think><answer> answer here </answer>\n",
      "To estimate the feasibility, utility and resource implications of electronically captured routine data for health technology assessment by randomised controlled trials (RCTs), and to recommend how routinely collected data could be made more effective for this purpose.Four health technology assessments that involved patients under care at five district general hospitals in the UK using four conditions from distinct classical specialties: inflammatory bowel disease, obstructive sleep apnoea, female urinary incontinence, and total knee replacement. Patient-identifiable, electronically stored routine data were sought from the administration and clinical database to provide the routine data.Four RCTs were replicated using routine data in place of the data already collected for the specific purpose of the assessments. This was done by modelling the research process from conception to final writing up and substituting routine for designed data activities at appropriate points. This allowed a direct comparison to be made of the costs and outcomes of the two approaches to health technology assessment. The trial designs were a two-centre randomised trial of outpatient follow-up; a single-centre randomised trial of two investigation techniques; a three-centre randomised trial of two surgical operations; and a single-centre randomised trial of perioperative anaesthetic intervention.Generally two-thirds of the research questions posed by health technology assessment through RCTs could be answered using routinely collected data. Where these questions required analysis of NHS resource use, data could usually be identified. Clinical effectiveness could also be judged, using proxy measures for quality of life, provided clinical symptoms and signs were collected in sufficient detail. Patient and professional preferences could not be identified from routine data but could be collected routinely by adapting existing instruments. Routine data were found potentially to be cheaper to extract and analyse than designed data, and they also facilitate recruitment as well as have the potential to identify patient outcomes captured in remote systems that may be missed in designed data collection. The study confirmed previous evidence that the validity of routinely collected data is suspect, particularly in systems that are not under clinical and professional control. Potential difficulties were also found in identifying, accessing and extracting data, as well as in the lack of uniformity in data structures, coding systems and definitions.\n",
      "Can randomised trials rely on existing electronic data?\n",
      "input tokens {'input_ids': tensor([[151646,     32,  10435,   1948,   2657,    323,  21388,     13,    576,\n",
      "           1196,  17064,    264,   3405,     11,    323,   2661,    264,   2266,\n",
      "             11,    279,  21388,  67477,    432,     13,    576,  17847,   1156,\n",
      "          15482,    911,    279,   2266,     11,   1221,   8473,    264,  32711,\n",
      "           1882,    304,    279,   3971,    323,   5499,   5707,    279,   1196,\n",
      "            448,    279,   4226,     13,    576,  32711,   1882,    323,   4226,\n",
      "            525,  43810,   2878,    220, 151648,    220, 151649,    323,    366,\n",
      "           9217,     29,    690,   9217,     29,   9492,     11,  15576,     11,\n",
      "            600,   1734,   2572,    220, 151648,  32711,   1882,   1588,    220,\n",
      "         151649,     27,   9217,     29,   4226,   1588,    690,   9217,    397,\n",
      "           1249,  16045,    279,  68443,     11,  15549,    323,   5101,  24154,\n",
      "            315,  70770,  17006,  14021,    821,    369,   2820,   5440,  15449,\n",
      "            553,   4194,   4056,  14071,  19080,    320,  74836,     82,    701,\n",
      "            323,    311,   6934,   1246,  38976,  14548,    821,   1410,    387,\n",
      "           1865,    803,   7373,    369,    419,   7428,    991,    413,   2820,\n",
      "           5440,  40200,    429,   6398,   6835,   1212,   2453,    518,   4236,\n",
      "           9290,   4586,  23551,    304,    279,   6424,   1667,   3040,   4682,\n",
      "            504,  12460,  28824,  93336,     25,  46188,  65258,   8457,     11,\n",
      "          53192,    533,   6084,   1443,   2152,  12508,     11,   8778,  71635,\n",
      "            304,  21319,    763,     11,    323,   2790,  21381,  13723,     13,\n",
      "          28924,     12,   1713,  22619,     11,  70770,   9768,  14021,    821,\n",
      "           1033,  16105,    504,    279,   8567,    323,  14490,   4625,    311,\n",
      "           3410,    279,  14021,    821,    991,    413,    431,   1162,     82,\n",
      "           1033,  71380,   1667,  14021,    821,    304,   1992,    315,    279,\n",
      "            821,   2669,  14548,    369,    279,   3151,   7428,    315,    279,\n",
      "          40200,     13,   1096,    572,   2814,    553,  60866,    279,   3412,\n",
      "           1882,    504,  42556,    311,   1590,   4378,    705,    323,  31334,\n",
      "          10607,  14021,    369,   6188,    821,   7488,    518,   8311,   3501,\n",
      "             13,   1096,   5420,    264,   2118,  12313,    311,    387,   1865,\n",
      "            315,    279,   7049,    323,  19554,    315,    279,   1378,  19827,\n",
      "            311,   2820,   5440,  15449,     13,    576,   9091,  14431,   1033,\n",
      "            264,   1378,  21217,    265,   4194,   4056,   9091,    315,  86130,\n",
      "           1795,   5239,     26,    264,   3175,  21217,    265,   4194,   4056,\n",
      "           9091,    315,   1378,   8814,  12538,     26,    264,   2326,  21217,\n",
      "            265,   4194,   4056,   9091,    315,   1378,  33833,   7525,     26,\n",
      "            323,    264,   3175,  21217,    265,   4194,   4056,   9091,    315,\n",
      "          61157,  42619,  40290,  70009,  20949,   1224,    798,    745,   1378,\n",
      "          44626,    315,    279,   3412,   4755,  36160,    553,   2820,   5440,\n",
      "          15449,   1526,    431,   1162,     82,   1410,    387,  18577,   1667,\n",
      "          38976,  14548,    821,     13,  10967,   1493,   4755,   2567,   6358,\n",
      "            315,  36281,   5101,    990,     11,    821,   1410,   5990,    387,\n",
      "          10820,     13,  32035,  26279,   1410,   1083,    387,  44387,     11,\n",
      "           1667,  13291,  10953,    369,   4271,    315,   2272,     11,   3897,\n",
      "          14490,  13495,    323,  11929,   1033,  14548,    304,  14016,   7716,\n",
      "             13,  28924,    323,   6584,  19322,   1410,    537,    387,  10820,\n",
      "            504,  14021,    821,    714,   1410,    387,  14548,  38976,    553,\n",
      "          69717,   6350,  23316,     13,  71062,    821,   1033,   1730,  13581,\n",
      "            311,    387,  23048,    311,   8649,    323,  48486,   1091,   6188,\n",
      "            821,     11,    323,    807,   1083,  27596,  33002,    438,   1632,\n",
      "            438,    614,    279,   4650,    311,  10542,   8720,  19554,  17006,\n",
      "            304,   8699,   5942,    429,   1231,    387,  13628,    304,   6188,\n",
      "            821,   4426,     13,    576,   3920,  10774,   3681,   5904,    429,\n",
      "            279,  31839,    315,  38976,  14548,    821,    374,  15207,     11,\n",
      "           7945,    304,   5942,    429,    525,    537,   1212,  14490,    323,\n",
      "           6584,   2524,     13,  53957,  26038,   1033,   1083,   1730,    304,\n",
      "          24588,     11,  31788,    323,  59408,    821,     11,    438,   1632,\n",
      "            438,    304,    279,   6853,    315,  13794,    487,    304,    821,\n",
      "          14389,     11,  10822,   5942,    323,  17473,    624,   6713,   4194,\n",
      "           4056,  19080,  17188,    389,   6350,  14346,    821,     30]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "outputs tensor([[151646,     32,  10435,   1948,   2657,    323,  21388,     13,    576,\n",
      "           1196,  17064,    264,   3405,     11,    323,   2661,    264,   2266,\n",
      "             11,    279,  21388,  67477,    432,     13,    576,  17847,   1156,\n",
      "          15482,    911,    279,   2266,     11,   1221,   8473,    264,  32711,\n",
      "           1882,    304,    279,   3971,    323,   5499,   5707,    279,   1196,\n",
      "            448,    279,   4226,     13,    576,  32711,   1882,    323,   4226,\n",
      "            525,  43810,   2878,    220, 151648,    220, 151649,    323,    366,\n",
      "           9217,     29,    690,   9217,     29,   9492,     11,  15576,     11,\n",
      "            600,   1734,   2572,    220, 151648,  32711,   1882,   1588,    220,\n",
      "         151649,     27,   9217,     29,   4226,   1588,    690,   9217,    397,\n",
      "           1249,  16045,    279,  68443,     11,  15549,    323,   5101,  24154,\n",
      "            315,  70770,  17006,  14021,    821,    369,   2820,   5440,  15449,\n",
      "            553,   4194,   4056,  14071,  19080,    320,  74836,     82,    701,\n",
      "            323,    311,   6934,   1246,  38976,  14548,    821,   1410,    387,\n",
      "           1865,    803,   7373,    369,    419,   7428,    991,    413,   2820,\n",
      "           5440,  40200,    429,   6398,   6835,   1212,   2453,    518,   4236,\n",
      "           9290,   4586,  23551,    304,    279,   6424,   1667,   3040,   4682,\n",
      "            504,  12460,  28824,  93336,     25,  46188,  65258,   8457,     11,\n",
      "          53192,    533,   6084,   1443,   2152,  12508,     11,   8778,  71635,\n",
      "            304,  21319,    763,     11,    323,   2790,  21381,  13723,     13,\n",
      "          28924,     12,   1713,  22619,     11,  70770,   9768,  14021,    821,\n",
      "           1033,  16105,    504,    279,   8567,    323,  14490,   4625,    311,\n",
      "           3410,    279,  14021,    821,    991,    413,    431,   1162,     82,\n",
      "           1033,  71380,   1667,  14021,    821,    304,   1992,    315,    279,\n",
      "            821,   2669,  14548,    369,    279,   3151,   7428,    315,    279,\n",
      "          40200,     13,   1096,    572,   2814,    553,  60866,    279,   3412,\n",
      "           1882,    504,  42556,    311,   1590,   4378,    705,    323,  31334,\n",
      "          10607,  14021,    369,   6188,    821,   7488,    518,   8311,   3501,\n",
      "             13,   1096,   5420,    264,   2118,  12313,    311,    387,   1865,\n",
      "            315,    279,   7049,    323,  19554,    315,    279,   1378,  19827,\n",
      "            311,   2820,   5440,  15449,     13,    576,   9091,  14431,   1033,\n",
      "            264,   1378,  21217,    265,   4194,   4056,   9091,    315,  86130,\n",
      "           1795,   5239,     26,    264,   3175,  21217,    265,   4194,   4056,\n",
      "           9091,    315,   1378,   8814,  12538,     26,    264,   2326,  21217,\n",
      "            265,   4194,   4056,   9091,    315,   1378,  33833,   7525,     26,\n",
      "            323,    264,   3175,  21217,    265,   4194,   4056,   9091,    315,\n",
      "          61157,  42619,  40290,  70009,  20949,   1224,    798,    745,   1378,\n",
      "          44626,    315,    279,   3412,   4755,  36160,    553,   2820,   5440,\n",
      "          15449,   1526,    431,   1162,     82,   1410,    387,  18577,   1667,\n",
      "          38976,  14548,    821,     13,  10967,   1493,   4755,   2567,   6358,\n",
      "            315,  36281,   5101,    990,     11,    821,   1410,   5990,    387,\n",
      "          10820,     13,  32035,  26279,   1410,   1083,    387,  44387,     11,\n",
      "           1667,  13291,  10953,    369,   4271,    315,   2272,     11,   3897,\n",
      "          14490,  13495,    323,  11929,   1033,  14548,    304,  14016,   7716,\n",
      "             13,  28924,    323,   6584,  19322,   1410,    537,    387,  10820,\n",
      "            504,  14021,    821,    714,   1410,    387,  14548,  38976,    553,\n",
      "          69717,   6350,  23316,     13,  71062,    821,   1033,   1730,  13581,\n",
      "            311,    387,  23048,    311,   8649,    323,  48486,   1091,   6188,\n",
      "            821,     11,    323,    807,   1083,  27596,  33002,    438,   1632,\n",
      "            438,    614,    279,   4650,    311,  10542,   8720,  19554,  17006,\n",
      "            304,   8699,   5942,    429,   1231,    387,  13628,    304,   6188,\n",
      "            821,   4426,     13,    576,   3920,  10774,   3681,   5904,    429,\n",
      "            279,  31839,    315,  38976,  14548,    821,    374,  15207,     11,\n",
      "           7945,    304,   5942,    429,    525,    537,   1212,  14490,    323,\n",
      "           6584,   2524,     13,  53957,  26038,   1033,   1083,   1730,    304,\n",
      "          24588,     11,  31788,    323,  59408,    821,     11,    438,   1632,\n",
      "            438,    304,    279,   6853,    315,  13794,    487,    304,    821,\n",
      "          14389,     11,  10822,   5942,    323,  17473,    624,   6713,   4194,\n",
      "           4056,  19080,  17188,    389,   6350,  14346,    821,     30,    576,\n",
      "           4226,    374,   9834,     11,    714,    432,   7460,  16585,  17879,\n",
      "            315,    279,    821,    594,   4271,    323,  40861,     13,    576,\n",
      "            821,   1969,    387,  31148,   1506,    311,   6016,   8720,  12345,\n",
      "             11,    323,    432,   1265,    387,  32930,    304,    264,   1616,\n",
      "            429,   3643,   6358,  42203,     13,    576,  19080,   1265,   2924,\n",
      "            264,   2524,   1874,    311,   5978,    429,    279,   3059,    525,\n",
      "            537,   4152,    311,   6012,     13,   2379,   1265,   1083,   2924,\n",
      "            264,   3460,   3322,   6077,   1379,    311,   5978,  28464,  25361,\n",
      "             13,    576,  15274,  10953,   1265,    387,  32332,   2348,   6350,\n",
      "          14490,   6540,    311,   5978,    429,    807,    525,  14720,     13,\n",
      "            576,  13026,   1265,    387,  15987,    911,    279,  15276,    323,\n",
      "           7567,    315,  23528,    304,    279,   9091,     13,    576,    821,\n",
      "           4426,   1265,    387,   2814,    304,    264,   1616,    429,    374,\n",
      "          11050,    323,  21187,   4756,   5975,     13,    576,   6358,   1265,\n",
      "            387,  13075,   1667,   8311,  28464,   5413,     13,    576,   3059,\n",
      "           1265,    387,   4652,    304,    264,  14397,  78704,   8322,    311,\n",
      "           5978,    429,    807,    525,  41910,     13,  27893,     11,   4194,\n",
      "           4056,  19080,    646,  17188,    389,   6350,  14346,    821,     11,\n",
      "            714,    432,   7460,  16585,   9115,    323,  11320,    311,   5978,\n",
      "            429,    279,    821,    374,    315,   1550,   4271,    323,    429,\n",
      "            279,   9091,    374,  30208,    323,  17821,    624, 151649,    271,\n",
      "            785,  68443,    315,   1667,  38976,  14548,    821,    304,   2820,\n",
      "           5440,  40200,   1526,  46241,  14071,  19080,    320,  74836,     82,\n",
      "              8,    646,    387,  20068,    553,  12831,   3807,   9363,     13,\n",
      "            576,   3920,   1730,    429,   8789,     11,   1378,  44626,    315,\n",
      "            279,   3412,   4755,  36160,    553,    431,   1162,     82,   1410,\n",
      "            387,  18577,   1667,  38976,  14548,    821,     13,   5976,    419,\n",
      "           5486,   1410,   3581,    882,    323,   7949,   7049,     11,    432,\n",
      "           1083,   2567,  16585,    821,  32189,    323,   6358,     13,  71062,\n",
      "            821,   1265,    387,  31148,   1506,    311,   6016,   8720,  12345,\n",
      "            323,  32930,    304,    264,   1616,    429,  72533,   6358,     13,\n",
      "            576,  19080,   1265,   2924,    264,   2524,   1874,     11,    264,\n",
      "           3460,   3322,   6077,   1379,     11,    323,  32332,  15274,  10953,\n",
      "             13,  51778]])\n",
      "response A conversation between User and Assistant. The user asks a question, and given a context, the Assistant solves it. The assistant first thinks about the context, then runs a reasoning process in the mind and finally provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think><answer> answer here </answer>\n",
      "To estimate the feasibility, utility and resource implications of electronically captured routine data for health technology assessment by randomised controlled trials (RCTs), and to recommend how routinely collected data could be made more effective for this purpose.Four health technology assessments that involved patients under care at five district general hospitals in the UK using four conditions from distinct classical specialties: inflammatory bowel disease, obstructive sleep apnoea, female urinary incontinence, and total knee replacement. Patient-identifiable, electronically stored routine data were sought from the administration and clinical database to provide the routine data.Four RCTs were replicated using routine data in place of the data already collected for the specific purpose of the assessments. This was done by modelling the research process from conception to final writing up and substituting routine for designed data activities at appropriate points. This allowed a direct comparison to be made of the costs and outcomes of the two approaches to health technology assessment. The trial designs were a two-centre randomised trial of outpatient follow-up; a single-centre randomised trial of two investigation techniques; a three-centre randomised trial of two surgical operations; and a single-centre randomised trial of perioperative anaesthetic intervention.Generally two-thirds of the research questions posed by health technology assessment through RCTs could be answered using routinely collected data. Where these questions required analysis of NHS resource use, data could usually be identified. Clinical effectiveness could also be judged, using proxy measures for quality of life, provided clinical symptoms and signs were collected in sufficient detail. Patient and professional preferences could not be identified from routine data but could be collected routinely by adapting existing instruments. Routine data were found potentially to be cheaper to extract and analyse than designed data, and they also facilitate recruitment as well as have the potential to identify patient outcomes captured in remote systems that may be missed in designed data collection. The study confirmed previous evidence that the validity of routinely collected data is suspect, particularly in systems that are not under clinical and professional control. Potential difficulties were also found in identifying, accessing and extracting data, as well as in the lack of uniformity in data structures, coding systems and definitions.\n",
      "Can randomised trials rely on existing electronic data? The answer is yes, but it requires careful consideration of the data's quality and relevance. The data must be anonymized to protect patient privacy, and it should be structured in a way that makes analysis feasible. The trials should include a control group to ensure that the results are not due to chance. They should also include a large enough sample size to ensure statistical significance. The outcome measures should be validated against existing clinical knowledge to ensure that they are reliable. The participants should be informed about the risks and benefits of participating in the trial. The data collection should be done in a way that is efficient and minimizes errors. The analysis should be conducted using appropriate statistical methods. The results should be published in a peer-reviewed journal to ensure that they are credible. Overall, randomised trials can rely on existing electronic data, but it requires careful planning and execution to ensure that the data is of high quality and that the trial is ethical and transparent.\n",
      "</think>\n",
      "\n",
      "The feasibility of using routinely collected data in health technology assessments through randomized controlled trials (RCTs) can be addressed by considering several factors. The study found that generally, two-thirds of the research questions posed by RCTs could be answered using routinely collected data. While this approach could save time and reduce costs, it also required careful data extraction and analysis. Routine data should be anonymized to protect patient privacy and structured in a way that facilitates analysis. The trials should include a control group, a large enough sample size, and validated outcome measures. Participants\n"
     ]
    }
   ],
   "source": [
    "dso = ds['train'].select(range(2)).map(extract_reasoning_and_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['pubid', 'question', 'context', 'long_answer', 'prompt', 'reasoning_graph', 'model_response'],\n",
      "    num_rows: 2\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"nodes\": [{\"id\": 0, \"text\": \" \"}], \"edges\": []}',\n",
       " '{\"nodes\": [{\"id\": 0, \"text\": \" \"}], \"edges\": []}']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dso['reasoning_graph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dso['model_response']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pubmed-qr-rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
