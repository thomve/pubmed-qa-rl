{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1887bf600d30486f886109a0b311fbd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"qiaojin/PubMedQA\", \"pqa_unlabeled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['pubid', 'question', 'context', 'long_answer'],\n",
      "        num_rows: 61249\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Although the use of alternative medicine in the United States is increasing, no published studies have documented the effectiveness of naturopathy for treatment of menopausal symptoms compared to women receiving conventional therapy in the clinical setting.', 'To compare naturopathic therapy with conventional medical therapy for treatment of selected menopausal symptoms.', 'A retrospective cohort study, using abstracted data from medical charts.', 'One natural medicine and six conventional medical clinics at Community Health Centers of King County, Washington, from November 1, 1996, through July 31, 1998.', 'Women aged 40 years of age or more with a diagnosis of menopausal symptoms documented by a naturopathic or conventional physician.', 'Improvement in selected menopausal symptoms.', 'In univariate analyses, patients treated with naturopathy for menopausal symptoms reported higher monthly incomes ($1848.00 versus $853.60), were less likely to be smokers (11.4% versus 41.9%), exercised more frequently, and reported higher frequencies of decreased energy (41.8% versus 24.4%), insomnia (57.0% versus 33.1%), and hot flashes (69.6% versus 55.6%) at baseline than those who received conventional treatment. In multivariate analyses, patients treated with naturopathy were approximately seven times more likely than conventionally treated patients to report improvement for insomnia (odds ratio [OR], 6.77; 95% confidence interval [CI], 1.71, 26.63) and decreased energy (OR, 6.55; 95% CI, 0.96, 44.74). Naturopathy patients reported improvement for anxiety (OR, 1.27; 95% CI, 0.63, 2.56), hot flashes (OR, 1.40; 95% CI, 0.68, 2.88), menstrual changes (OR, 0.98; 95% CI, 0.43, 2.24), and vaginal dryness (OR, 0.91; 95% CI, 0.21, 3.96) about as frequently as patients who were treated conventionally.']\n"
     ]
    }
   ],
   "source": [
    "print(ds['train'][0]['context']['contexts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = (\n",
    "    \"A conversation between User and Assistant. The user asks a question, and given a context, the Assistant solves it. The assistant \"\n",
    "    \"first thinks about the context, then reasoning process in the mind and then provides the user with the answer. The reasoning \"\n",
    "    \"process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., \"\n",
    "    \"<think> reasoning process here </think><answer> answer here </answer>\"\n",
    ")\n",
    "\n",
    "def make_conversation(example):\n",
    "    return {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": \"\".join(example[\"context\"]['contexts'])},\n",
    "            {\"role\": \"user\", \"content\": example[\"question\"]},\n",
    "        ],\n",
    "    }\n",
    "\n",
    "dds = ds.map(make_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['pubid', 'question', 'context', 'long_answer', 'prompt'],\n",
       "        num_rows: 61249\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'A conversation between User and Assistant. The user asks a question, and given a context, the Assistant solves it. The assistant first thinks about the context, then reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think><answer> answer here </answer>',\n",
       "  'role': 'system'},\n",
       " {'content': 'Although the use of alternative medicine in the United States is increasing, no published studies have documented the effectiveness of naturopathy for treatment of menopausal symptoms compared to women receiving conventional therapy in the clinical setting.To compare naturopathic therapy with conventional medical therapy for treatment of selected menopausal symptoms.A retrospective cohort study, using abstracted data from medical charts.One natural medicine and six conventional medical clinics at Community Health Centers of King County, Washington, from November 1, 1996, through July 31, 1998.Women aged 40 years of age or more with a diagnosis of menopausal symptoms documented by a naturopathic or conventional physician.Improvement in selected menopausal symptoms.In univariate analyses, patients treated with naturopathy for menopausal symptoms reported higher monthly incomes ($1848.00 versus $853.60), were less likely to be smokers (11.4% versus 41.9%), exercised more frequently, and reported higher frequencies of decreased energy (41.8% versus 24.4%), insomnia (57.0% versus 33.1%), and hot flashes (69.6% versus 55.6%) at baseline than those who received conventional treatment. In multivariate analyses, patients treated with naturopathy were approximately seven times more likely than conventionally treated patients to report improvement for insomnia (odds ratio [OR], 6.77; 95% confidence interval [CI], 1.71, 26.63) and decreased energy (OR, 6.55; 95% CI, 0.96, 44.74). Naturopathy patients reported improvement for anxiety (OR, 1.27; 95% CI, 0.63, 2.56), hot flashes (OR, 1.40; 95% CI, 0.68, 2.88), menstrual changes (OR, 0.98; 95% CI, 0.43, 2.24), and vaginal dryness (OR, 0.91; 95% CI, 0.21, 3.96) about as frequently as patients who were treated conventionally.',\n",
       "  'role': 'user'},\n",
       " {'content': 'Is naturopathy as effective as conventional therapy for treatment of menopausal symptoms?',\n",
       "  'role': 'user'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds['train'][0]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pubid': 14499049,\n",
       " 'question': 'Can randomised trials rely on existing electronic data?',\n",
       " 'context': {'contexts': ['To estimate the feasibility, utility and resource implications of electronically captured routine data for health technology assessment by randomised controlled trials (RCTs), and to recommend how routinely collected data could be made more effective for this purpose.',\n",
       "   'Four health technology assessments that involved patients under care at five district general hospitals in the UK using four conditions from distinct classical specialties: inflammatory bowel disease, obstructive sleep apnoea, female urinary incontinence, and total knee replacement. Patient-identifiable, electronically stored routine data were sought from the administration and clinical database to provide the routine data.',\n",
       "   'Four RCTs were replicated using routine data in place of the data already collected for the specific purpose of the assessments. This was done by modelling the research process from conception to final writing up and substituting routine for designed data activities at appropriate points. This allowed a direct comparison to be made of the costs and outcomes of the two approaches to health technology assessment. The trial designs were a two-centre randomised trial of outpatient follow-up; a single-centre randomised trial of two investigation techniques; a three-centre randomised trial of two surgical operations; and a single-centre randomised trial of perioperative anaesthetic intervention.',\n",
       "   'Generally two-thirds of the research questions posed by health technology assessment through RCTs could be answered using routinely collected data. Where these questions required analysis of NHS resource use, data could usually be identified. Clinical effectiveness could also be judged, using proxy measures for quality of life, provided clinical symptoms and signs were collected in sufficient detail. Patient and professional preferences could not be identified from routine data but could be collected routinely by adapting existing instruments. Routine data were found potentially to be cheaper to extract and analyse than designed data, and they also facilitate recruitment as well as have the potential to identify patient outcomes captured in remote systems that may be missed in designed data collection. The study confirmed previous evidence that the validity of routinely collected data is suspect, particularly in systems that are not under clinical and professional control. Potential difficulties were also found in identifying, accessing and extracting data, as well as in the lack of uniformity in data structures, coding systems and definitions.'],\n",
       "  'labels': ['OBJECTIVES', 'DATA SOURCES', 'REVIEW METHODS', 'RESULTS'],\n",
       "  'meshes': ['Arthroplasty, Replacement, Knee',\n",
       "   'Bias',\n",
       "   'Blood Transfusion, Autologous',\n",
       "   'Data Collection',\n",
       "   'Feasibility Studies',\n",
       "   'Humans',\n",
       "   'Inflammatory Bowel Diseases',\n",
       "   'Randomized Controlled Trials as Topic',\n",
       "   'Reproducibility of Results',\n",
       "   'Research Design',\n",
       "   'Sleep Apnea, Obstructive',\n",
       "   'Technology Assessment, Biomedical',\n",
       "   'Urinary Incontinence']},\n",
       " 'long_answer': 'Routine data have the potential to support health technology assessment by RCTs. The cost of data collection and analysis is likely to fall, although further work is required to improve the validity of routine data, particularly in central returns. Better knowledge of the capability of local systems and access to the data held on them is also essential. Routinely captured clinical data have real potential to measure patient outcomes, particularly if the detail and precision of the data could be improved.',\n",
       " 'prompt': [{'content': 'A conversation between User and Assistant. The user asks a question, and given a context, the Assistant solves it. The assistant first thinks about the context, then reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think><answer> answer here </answer>',\n",
       "   'role': 'system'},\n",
       "  {'content': 'To estimate the feasibility, utility and resource implications of electronically captured routine data for health technology assessment by randomised controlled trials (RCTs), and to recommend how routinely collected data could be made more effective for this purpose.Four health technology assessments that involved patients under care at five district general hospitals in the UK using four conditions from distinct classical specialties: inflammatory bowel disease, obstructive sleep apnoea, female urinary incontinence, and total knee replacement. Patient-identifiable, electronically stored routine data were sought from the administration and clinical database to provide the routine data.Four RCTs were replicated using routine data in place of the data already collected for the specific purpose of the assessments. This was done by modelling the research process from conception to final writing up and substituting routine for designed data activities at appropriate points. This allowed a direct comparison to be made of the costs and outcomes of the two approaches to health technology assessment. The trial designs were a two-centre randomised trial of outpatient follow-up; a single-centre randomised trial of two investigation techniques; a three-centre randomised trial of two surgical operations; and a single-centre randomised trial of perioperative anaesthetic intervention.Generally two-thirds of the research questions posed by health technology assessment through RCTs could be answered using routinely collected data. Where these questions required analysis of NHS resource use, data could usually be identified. Clinical effectiveness could also be judged, using proxy measures for quality of life, provided clinical symptoms and signs were collected in sufficient detail. Patient and professional preferences could not be identified from routine data but could be collected routinely by adapting existing instruments. Routine data were found potentially to be cheaper to extract and analyse than designed data, and they also facilitate recruitment as well as have the potential to identify patient outcomes captured in remote systems that may be missed in designed data collection. The study confirmed previous evidence that the validity of routinely collected data is suspect, particularly in systems that are not under clinical and professional control. Potential difficulties were also found in identifying, accessing and extracting data, as well as in the lack of uniformity in data structures, coding systems and definitions.',\n",
       "   'role': 'user'},\n",
       "  {'content': 'Can randomised trials rely on existing electronic data?',\n",
       "   'role': 'user'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['long_answer', 'prompt'],\n",
      "        num_rows: 61249\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dds.remove_columns(['pubid', 'question', 'context'])\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_id = \"Qwen/Qwen2-0.5B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 540,672 || all params: 494,573,440 || trainable%: 0.1093\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def format_reward(completions, **kwargs):\n",
    "    pattern = r\"^<think>.*?</think>\\s*<answer>.*?</answer>$\"\n",
    "    completion_contents = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, content) for content in completion_contents]\n",
    "    rewards_list = [1.0 if match else 0.0 for match in matches]\n",
    "    return [1.0 if match else 0.0 for match in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load a pretrained SBERT model\n",
    "encoding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def get_similarity(paragraph1, paragraph2):\n",
    "    embedding1 = encoding_model.encode(paragraph1, convert_to_tensor=True)\n",
    "    embedding2 = encoding_model.encode(paragraph2, convert_to_tensor=True)\n",
    "    similarity = util.pytorch_cos_sim(embedding1, embedding2).item()\n",
    "    return similarity\n",
    "\n",
    "def reward_function(completions, **kwargs):\n",
    "    long_answers = kwargs[\"long_answer\"]\n",
    "    completion_contents = [completion[0][\"content\"] for completion in completions]\n",
    "    rewards = []\n",
    "    for content, long_answer in zip(completion_contents, long_answers):\n",
    "        similarity = get_similarity(content, long_answer)\n",
    "        if similarity > 0.9:\n",
    "            rewards.append(1.)\n",
    "        elif similarity > 0.7:\n",
    "            rewards.append(0.5)\n",
    "        elif similarity > 0.5:\n",
    "            rewards.append(0.0)\n",
    "        else:\n",
    "            rewards.append(-1.0)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOConfig\n",
    "\n",
    "# Configure training arguments using GRPOConfig\n",
    "training_args = GRPOConfig(\n",
    "    output_dir=\"Qwen2-0.5B-GRPO-test\",\n",
    "    learning_rate=1e-5,\n",
    "    remove_unused_columns=False, # to access the solution column in accuracy_reward\n",
    "    gradient_accumulation_steps=16,\n",
    "    num_train_epochs=1,\n",
    "    bf16=True,\n",
    "\n",
    "    # Parameters that control de data preprocessing\n",
    "    max_completion_length=64, # default: 256\n",
    "    num_generations=4, # default: 8\n",
    "    max_prompt_length=128, # default: 512\n",
    "\n",
    "    # Parameters related to reporting and saving\n",
    "    report_to=[\"tensorboard\"],\n",
    "    logging_steps=10,\n",
    "    push_to_hub=True,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOTrainer\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    reward_funcs=[format_reward, reward_function],\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset['train']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='3828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   6/3828 03:50 < 61:15:37, 0.02 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pubmed-qr-rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
